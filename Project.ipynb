{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"TrumpvsBiden.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import tweepy \n",
    "from tweepy import OAuthHandler \n",
    "from textblob import TextBlob \n",
    "import matplotlib.pyplot as plt\n",
    "#from wordcloud import WordCloud \n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import itertools\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vaderSentiment\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\avinash\\anaconda3\\lib\\site-packages (from vaderSentiment) (2.18.4)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\avinash\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in c:\\users\\avinash\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in c:\\users\\avinash\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\avinash\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2018.4.16)\n",
      "Installing collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Avinash\\Anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = 'Fkq1YtWMXJfm7rqFQe6bUMKnk'\n",
    "consumer_secret = 'tbQFEXaYskF6vfHMN0xpBhjuDGIYP6vpNk4TYEsbn3ETOj6YKY'\n",
    "access_token = '1254116935006072833-4lYrmDIsHq9wbVan3VDtdzwkeWe6Nc'\n",
    "access_token_secret = 'f9zpd5uYABZCiK28Cixp5kR3dy6bFbXybDfwiWRMFvaa3'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "authenticate= tweepy.OAuthHandler(consumer_key,consumer_secret)\n",
    "authenticate.set_access_token(access_token,access_token_secret)\n",
    "api= tweepy.API(authenticate, wait_on_rate_limit= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1)Day 13- Day 22\n",
      "Started revising the java. From primitive and non-primitive data types to interfaces,inheritance,Typecasting- covered all these with practice problems . The idea is to strengthen the core concepts of java before building the open apps. @OAN_OpenApps \n",
      "#100DaysOfCode\n",
      "\n",
      "2)Day 12:\n",
      "Too much reading without coding is not good in the path of learning in the tech world. So, started coding in Java and created the genesis block, first block and second block of the blockchain. Full code from the scratch on GitHub.\n",
      "@OAN_OpenApps #Blockchain \n",
      "#100DaysOfCode\n",
      "\n",
      "3)Day 11:\n",
      "Read about forking - Hard fork and Soft fork in details which also lead to me knowing how Bitcoin cash came into existence. \n",
      "@OAN_OpenApps \n",
      "#Bitcoin #Blockchain #Ethereum\n",
      "#100DaysOfCode\n",
      "\n",
      "4)The hard work put in by the @blockchainedind team in preparing the structure of #100DaysOfCode program is so visible when you are part of the program. Currently I am on Day 20 and I never needed to look for other sources outside of the material they provide.Brilliant!\n",
      "#Blockchain\n",
      "\n",
      "5)Day 10:\n",
      "Jumped to hash function and read about popular hash functions like SHA-256, MD 5, Keccak-256 etc. Also got to know how double spending is tackled in the bitcoin network.\n",
      "@OAN_OpenApps @blockchainedind \n",
      "#blockchain #Bitcoin \n",
      "#100DaysOfCode\n",
      "\n",
      "6)Day 9:\n",
      "On this day, i learnt about symmetric and asymmetric  cryptography, how public and private keys are used and how digital signatures are used to sign transactions.\n",
      "This is a topic of my interest. So went a step further to read about popular algos like AES,DES\n",
      "#100DaysOfCode\n",
      "\n",
      "7)Day 8:\n",
      "This day was characterised by reading about basic #ethereum  terminologies like how gas price and gas limit works.\n",
      "#100DaysOfCode\n",
      "\n",
      "8)Day 7:\n",
      "Learnt about the alternatives of POW. Those are Proof of Stake, proof of Burn, Proof of Capacity, Proof of Elapsed Time and Proof of Activity. POS is gaining much popularity these days as Ethereum 2.0 is implementing it. \n",
      "@OAN_OpenApps \n",
      "#100DaysOfCode\n",
      "\n",
      "9)Day 6:\n",
      "On my way to learn about the open application network, I used this day to understand the core concepts behind the proof-of-work, the advantages it provide, the challenges and the threats behind using this protocol.\n",
      "@OAN_OpenApps \n",
      "#100DaysOfCode\n",
      "\n",
      "10)Day 5:\n",
      "This day was invested in understanding the block anatomy like nonce, merkle tree, timestamp etc and an overview of consensus mechanism followed by the network.\n",
      "#100DaysOfCode\n",
      "\n",
      "11)Day 4:\n",
      "Permissioned blockchains always gave tough time to me. So decided to invest this day to clear all my doubts regarding how group of organisations also can regulate the blockchain for the specific use cases albeit it raises question over decentralisation.\n",
      "#100DaysOfCode\n",
      "\n",
      "12)@RobotProud Thanks RobotüòÅ\n",
      "\n",
      "13)Day 3:\n",
      "Dived deeper into the concepts of how candidate blocks work by collecting transactions, the nonce, the public and private blockchains. Also covered how blockchain is being used in industries for voting, supply chain, digital certificates etc.\n",
      "#100DaysOfCode\n",
      "\n",
      "14)Day 2:\n",
      "Jumped into bitcoin mining part and the consensus algorithm used in the network. The miners are awarded for the resources they use to compute the complex mathematical problem and receive the reward which is halved after every 210000 + transaction fees.\n",
      "#100DaysOfCode\n",
      "\n",
      "15)Day 1:\n",
      "The content of the first day focussed on Bitcoin and how it paved the way for other applications in blockchain over the years, how blockchain is different from centralised systems, distributed ledger and transaction verification.\n",
      "#100DaysOfCode\n",
      "\n",
      "16)Thread:\n",
      "#100DaysOfCode under @blockchainedind @OAN_OpenApps \n",
      "The onboarding of 40+ selected students and professionals happened on 2nd oct where we were introduced to each other. The session also laid emphasis on the relevance and significance of open application networks .\n",
      "\n",
      "17)The ongoing #covid19 has also seen the rise of number of scams in the name of internships. Apparently, students are asked to sell some courses and are awarded internship certificatesüòÅ. What the hell am I supposed to do with that certificate? Can't even flaunt.\n",
      "\n",
      "18)RT @Melt_Dem: 1/ the crypto fundraising scene is *crazy* right now. \n",
      "\n",
      "there's so much money chasing every deal, so many new funds, and ever‚Ä¶\n",
      "\n",
      "19)That phase of the life when I started learning #MachineLearning . Finally I think now I am eligible enough to write 'Machine Learning Enthusiast' in my bio.\n",
      "\n",
      "20)When nobody is attending your webinar, call  google, employees and organise a webinar with a fancy poster titled- \"How to get job in google\". It will surely work.\n",
      "#Trends\n",
      "\n",
      "21)Are you even a cofounder if you are not virtue signalling on @LinkedIn with 500 words posts regularly?\n",
      "\n",
      "22)RT @aparanjape: M.S. Dhoni - a great compilation by @Amul_Coop \n",
      "\n",
      "https://t.co/67cP7qj1SL\n",
      "\n"
     ]
    }
   ],
   "source": [
    "posts = api.user_timeline(screen_name = 'avi_avi_nash', count = 100, lang='en',tweet_mode=\"extended\")\n",
    "i=1\n",
    "for tweet in posts[0:22]:\n",
    "    print(str(i)+\")\"+tweet.full_text+\"\\n\")\n",
    "    i+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Day 13- Day 22\\nStarted revising the java. Fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Day 12:\\nToo much reading without coding is no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Day 11:\\nRead about forking - Hard fork and So...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The hard work put in by the @blockchainedind t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Day 10:\\nJumped to hash function and read abou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets\n",
       "0  Day 13- Day 22\\nStarted revising the java. Fro...\n",
       "1  Day 12:\\nToo much reading without coding is no...\n",
       "2  Day 11:\\nRead about forking - Hard fork and So...\n",
       "3  The hard work put in by the @blockchainedind t...\n",
       "4  Day 10:\\nJumped to hash function and read abou..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= pd.DataFrame([tweet.full_text for tweet in posts],columns=['Tweets'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet): \n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Tweets']= data['Tweets'].apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Day 13 Day 22 Started revising the java From p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Day 12 Too much reading without coding is not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Day 11 Read about forking Hard fork and Soft f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The hard work put in by the team in preparing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Day 10 Jumped to hash function and read about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Day 9 On this day i learnt about symmetric and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Day 8 This day was characterised by reading ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Day 7 Learnt about the alternatives of POW Tho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Day 6 On my way to learn about the open applic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Day 5 This day was invested in understanding t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Day 4 Permissioned blockchains always gave tou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Thanks Robot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Day 3 Dived deeper into the concepts of how ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Day 2 Jumped into bitcoin mining part and the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Day 1 The content of the first day focussed on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Thread 100DaysOfCode under OpenApps The onboar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The ongoing covid19 has also seen the rise of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RT Dem 1 the crypto fundraising scene is crazy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>That phase of the life when I started learning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>When nobody is attending your webinar call goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Are you even a cofounder if you are not virtue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RT M S Dhoni a great compilation by Coop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>io This is brilliant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RT Interacting with our bright young minds at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>comment interested</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RT Das Kapital in a nutshell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Hackout Hackoffv2 0 HackJaipur Last year i sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>RT Let s clear this misinformation This is com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RT Also submit this RTI reply from RBI and spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>I have a joke on my university but it might in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>ratna Bitcoin price post halving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>RT ratna The case for censorship resistant mon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>RT Twitter comments gt gt gt Original tweet Al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>This decade will see the growth of matic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>So it turned out that the coins which were ina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>What So are we going to know who Satoshi Nakam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Many are losing their faith in Bitcoin as the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>RT Bitcoin 2018 DeFi is bullshit 2020 Bitcoin ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>RT 0 Web 3 Power pack guide All the budding De...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Others I am the jack of all ships master of no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>rowling Now waiting for your own wallet whose ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Decentralised world is on its way Bitcoin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>If you like tech talks more than ted talks the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>I like this idea of issuing the ERC20 tokens a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>This is huge Tokens MOONS and BRICKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>RT Jhaveri Economic Package for Migrants FREE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>RT Jhaveri Economic Package for Migrants Big f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>I take back my words Online exams are even big...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>RT Jhaveri Update India has now ramped the pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>First they ignore you Then they laugh at you T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>RT Mainnet is going live The launch sequence s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>ratna Came to know about your journey with and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Insightful event Found it more interesting bec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Besides political twitter there is another sid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Those who question Bitcoin and refuse to accep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>From 12 to 8500 and still going the success st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>This was my first bitcoinhalving The last bloc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>On the first BitcoinHalving in 2012 bitcoin pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Doesn t look like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>24 hours 164 blocks into Bitcoin halving</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweets\n",
       "0   Day 13 Day 22 Started revising the java From p...\n",
       "1   Day 12 Too much reading without coding is not ...\n",
       "2   Day 11 Read about forking Hard fork and Soft f...\n",
       "3   The hard work put in by the team in preparing ...\n",
       "4   Day 10 Jumped to hash function and read about ...\n",
       "5   Day 9 On this day i learnt about symmetric and...\n",
       "6   Day 8 This day was characterised by reading ab...\n",
       "7   Day 7 Learnt about the alternatives of POW Tho...\n",
       "8   Day 6 On my way to learn about the open applic...\n",
       "9   Day 5 This day was invested in understanding t...\n",
       "10  Day 4 Permissioned blockchains always gave tou...\n",
       "11                                       Thanks Robot\n",
       "12  Day 3 Dived deeper into the concepts of how ca...\n",
       "13  Day 2 Jumped into bitcoin mining part and the ...\n",
       "14  Day 1 The content of the first day focussed on...\n",
       "15  Thread 100DaysOfCode under OpenApps The onboar...\n",
       "16  The ongoing covid19 has also seen the rise of ...\n",
       "17  RT Dem 1 the crypto fundraising scene is crazy...\n",
       "18  That phase of the life when I started learning...\n",
       "19  When nobody is attending your webinar call goo...\n",
       "20  Are you even a cofounder if you are not virtue...\n",
       "21           RT M S Dhoni a great compilation by Coop\n",
       "22                               io This is brilliant\n",
       "23  RT Interacting with our bright young minds at ...\n",
       "24                                 comment interested\n",
       "25                       RT Das Kapital in a nutshell\n",
       "26  Hackout Hackoffv2 0 HackJaipur Last year i sta...\n",
       "27  RT Let s clear this misinformation This is com...\n",
       "28  RT Also submit this RTI reply from RBI and spe...\n",
       "29  I have a joke on my university but it might in...\n",
       "..                                                ...\n",
       "69                   ratna Bitcoin price post halving\n",
       "70  RT ratna The case for censorship resistant mon...\n",
       "71  RT Twitter comments gt gt gt Original tweet Al...\n",
       "72           This decade will see the growth of matic\n",
       "73  So it turned out that the coins which were ina...\n",
       "74  What So are we going to know who Satoshi Nakam...\n",
       "75  Many are losing their faith in Bitcoin as the ...\n",
       "76  RT Bitcoin 2018 DeFi is bullshit 2020 Bitcoin ...\n",
       "77  RT 0 Web 3 Power pack guide All the budding De...\n",
       "78  Others I am the jack of all ships master of no...\n",
       "79  rowling Now waiting for your own wallet whose ...\n",
       "80          Decentralised world is on its way Bitcoin\n",
       "81  If you like tech talks more than ted talks the...\n",
       "82  I like this idea of issuing the ERC20 tokens a...\n",
       "83               This is huge Tokens MOONS and BRICKS\n",
       "84  RT Jhaveri Economic Package for Migrants FREE ...\n",
       "85  RT Jhaveri Economic Package for Migrants Big f...\n",
       "86  I take back my words Online exams are even big...\n",
       "87  RT Jhaveri Update India has now ramped the pro...\n",
       "88  First they ignore you Then they laugh at you T...\n",
       "89  RT Mainnet is going live The launch sequence s...\n",
       "90  ratna Came to know about your journey with and...\n",
       "91  Insightful event Found it more interesting bec...\n",
       "92  Besides political twitter there is another sid...\n",
       "93  Those who question Bitcoin and refuse to accep...\n",
       "94  From 12 to 8500 and still going the success st...\n",
       "95  This was my first bitcoinhalving The last bloc...\n",
       "96  On the first BitcoinHalving in 2012 bitcoin pr...\n",
       "97                                  Doesn t look like\n",
       "98           24 hours 164 blocks into Bitcoin halving\n",
       "\n",
       "[99 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentiment Analysis Tool\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from stop_words import get_stop_words\n",
    "import operator\n",
    "import re\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('TrumpvsBiden', 'a') as f:\n",
    "    f.write(\n",
    "        data.to_string(header = False, index = False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PresidentialElectionTrumpvsBiden\n",
      "What do you want to do?\n",
      "1 - show sentiment distribution in a text\n",
      "2 - show a pie chart of sentiment distribution\n",
      "3 - show a list of all positive words\n",
      "4 - show a list of all negative words\n",
      "5 - show a chart with top positive words\n",
      "6 - show a chart with top negative words\n",
      "7 - show sentiment distribution for text without redundant words\n",
      "8 - show a pie chart of sentiment distribution for text without redundant words\n",
      "9 - show sentiment distribution for sentences with provided keyword\n",
      "10 - quit \n",
      "Press the number:1\n",
      "Sentiment distribution for TrumpvsBiden\n",
      "Positive: 2.96% Negative: 2.37% Neutral:94.67%\n",
      "What do you want to do?\n",
      "1 - show sentiment distribution in a text\n",
      "2 - show a pie chart of sentiment distribution\n",
      "3 - show a list of all positive words\n",
      "4 - show a list of all negative words\n",
      "5 - show a chart with top positive words\n",
      "6 - show a chart with top negative words\n",
      "7 - show sentiment distribution for text without redundant words\n",
      "8 - show a pie chart of sentiment distribution for text without redundant words\n",
      "9 - show sentiment distribution for sentences with provided keyword\n",
      "10 - quit \n",
      "Press the number:2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What do you want to do?\n",
      "1 - show sentiment distribution in a text\n",
      "2 - show a pie chart of sentiment distribution\n",
      "3 - show a list of all positive words\n",
      "4 - show a list of all negative words\n",
      "5 - show a chart with top positive words\n",
      "6 - show a chart with top negative words\n",
      "7 - show sentiment distribution for text without redundant words\n",
      "8 - show a pie chart of sentiment distribution for text without redundant words\n",
      "9 - show sentiment distribution for sentences with provided keyword\n",
      "10 - quit \n",
      "Press the number:3\n",
      "good----------- 1\n",
      "soft----------- 1\n",
      "popular-------- 1\n",
      "tough---------- 1\n",
      "right---------- 1\n",
      "What do you want to do?\n",
      "1 - show sentiment distribution in a text\n",
      "2 - show a pie chart of sentiment distribution\n",
      "3 - show a list of all positive words\n",
      "4 - show a list of all negative words\n",
      "5 - show a chart with top positive words\n",
      "6 - show a chart with top negative words\n",
      "7 - show sentiment distribution for text without redundant words\n",
      "8 - show a pie chart of sentiment distribution for text without redundant words\n",
      "9 - show sentiment distribution for sentences with provided keyword\n",
      "10 - quit \n",
      "Press the number:4\n",
      "primitive------ 1\n",
      "hard----------- 1\n",
      "scam----------- 1\n",
      "crazy---------- 1\n",
      "What do you want to do?\n",
      "1 - show sentiment distribution in a text\n",
      "2 - show a pie chart of sentiment distribution\n",
      "3 - show a list of all positive words\n",
      "4 - show a list of all negative words\n",
      "5 - show a chart with top positive words\n",
      "6 - show a chart with top negative words\n",
      "7 - show sentiment distribution for text without redundant words\n",
      "8 - show a pie chart of sentiment distribution for text without redundant words\n",
      "9 - show sentiment distribution for sentences with provided keyword\n",
      "10 - quit \n",
      "Press the number:5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What do you want to do?\n",
      "1 - show sentiment distribution in a text\n",
      "2 - show a pie chart of sentiment distribution\n",
      "3 - show a list of all positive words\n",
      "4 - show a list of all negative words\n",
      "5 - show a chart with top positive words\n",
      "6 - show a chart with top negative words\n",
      "7 - show sentiment distribution for text without redundant words\n",
      "8 - show a pie chart of sentiment distribution for text without redundant words\n",
      "9 - show sentiment distribution for sentences with provided keyword\n",
      "10 - quit \n"
     ]
    }
   ],
   "source": [
    "a=input(\"PresidentialElection\")\n",
    "\n",
    "\n",
    "def read_file(file=a):\n",
    "    file=open(file,'r')\n",
    "    text=file.read().lower()\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "stop_words = get_stop_words('english')\n",
    "positive=read_file('positive-words.txt').split('\\n')\n",
    "negative=read_file('negative-words.txt').split('\\n')\n",
    "p=0\n",
    "pintxt=[]\n",
    "n=0\n",
    "nintxt=[]\n",
    "e=0  #neutralne\n",
    "eintxt=[]\n",
    "\n",
    "b= read_file()\n",
    "\n",
    "def file_to_sentences(text=b):\n",
    "    text=text.replace(\",\",\" \")\n",
    "    sentences = re.split(r' *[\\.\\?!][\\'\"\\)\\]]* *', text)\n",
    "    return sentences\n",
    "sentences=file_to_sentences()\n",
    "\n",
    "def file_to_text(file=b):\n",
    "    file=file.translate(str.maketrans('','',string.punctuation)).lower()\n",
    "    file=file.split()\n",
    "    return file\n",
    "text=file_to_text()\n",
    "\n",
    "for i in text:\n",
    "    if i in positive:\n",
    "        p+=1\n",
    "        pintxt.append(i)\n",
    "    elif i in negative:\n",
    "        n+=1\n",
    "        nintxt.append(i)\n",
    "    else:\n",
    "        e+=1\n",
    "        eintxt.append(i)\n",
    "\n",
    "def procent(object,text):\n",
    "    m=object/len(text)*100\n",
    "    m=format(float(m),'.2f')\n",
    "    return m+'%'\n",
    "def print_percentage():\n",
    "    print('Sentiment distribution for',a)\n",
    "    print('Positive:', procent(p, text), 'Negative:', procent(n, text), 'Neutral:' + procent(e, text))\n",
    "def pie_chart():\n",
    "    dane=[p,n,e]\n",
    "    labels=['Positive','Negative','Neutral']\n",
    "    plt.pie(dane,labels=labels,autopct='%1.2f%%',colors=['g','r','gold'])\n",
    "    k='Sentiment Analysis for: '+a\n",
    "    plt.title(k)\n",
    "    plt.show()\n",
    "counterp = collections.Counter(pintxt)\n",
    "countern = collections.Counter(nintxt)\n",
    "pmc=counterp.most_common()#positive most common\n",
    "nmc=countern.most_common()#negative most common\n",
    "\n",
    "#sortowanie list malejƒÖco\n",
    "pmc.sort(key=operator.itemgetter(1),reverse=True)\n",
    "nmc.sort(key=operator.itemgetter(1),reverse=True)\n",
    "\n",
    "#funkcja drukuje podanƒÖ ilo≈õƒá najpopularniejszych pozytywnych s≈Ç√≥w w tek≈õcie.\n",
    "#domy≈õlnie podaje listƒô wszystkich pozytywnych s≈Ç√≥w jakie wystƒÖpi≈Çy w tek≈õƒáie\n",
    "def pos_words_list(n=len(pmc)):\n",
    "    s≈Çowo = [x[0] for x in pmc]\n",
    "    ilo≈õƒá = [x[1] for x in pmc]\n",
    "    for i in range(n):\n",
    "        print(\"{:-<15} {}\".format(s≈Çowo[i], ilo≈õƒá[i]))\n",
    "\n",
    "#funkcja drukuje podanƒÖ ilo≈õƒá najpopularniejszych negatywnych s≈Ç√≥w w tek≈õcie.\n",
    "#domy≈õlnie podaje listƒô wszystkich negatywnych s≈Ç√≥w jakie wystƒÖpi≈Çy w tek≈õƒáie\n",
    "def neg_words_list(n=len(nmc)):\n",
    "    s≈Çowo = [x[0] for x in nmc]\n",
    "    ilo≈õƒá = [x[1] for x in nmc]\n",
    "    for i in range(n):\n",
    "        print(\"{:-<15} {}\".format(s≈Çowo[i], ilo≈õƒá[i]))\n",
    "\n",
    "\n",
    "def top_5_words(list):\n",
    "    x_val = [x[0] for x in list]\n",
    "    if len(list)>5:\n",
    "        top_5_words=[]\n",
    "        for i in range(5):\n",
    "            top_5_words.append(x_val[i])\n",
    "        return top_5_words\n",
    "    else:\n",
    "        return x_val\n",
    "\n",
    "def top_5_numbers(list):\n",
    "    y_val = [x[1] for x in list]\n",
    "    if len(list)>5:\n",
    "        top_5_numbers=[]\n",
    "        for i in range(5):\n",
    "            top_5_numbers.append(y_val[i])\n",
    "        return top_5_numbers\n",
    "    else:\n",
    "        return y_val\n",
    "\n",
    "def pos_chart():\n",
    "    plt.bar(top_5_words(pmc),top_5_numbers(pmc),color='g')\n",
    "    plt.show()\n",
    "\n",
    "def neg_chart():\n",
    "    plt.bar(top_5_words(nmc),top_5_numbers(nmc),color='r')\n",
    "    plt.show()\n",
    "\n",
    "text1=file_to_text(b)\n",
    "def stopped_text(text1=text1):\n",
    "    for i in text1:\n",
    "        if i in stop_words:\n",
    "            text1.remove(i)\n",
    "    return text1\n",
    "\n",
    "stop = stopped_text()\n",
    "ps=0\n",
    "ns=0\n",
    "es=0\n",
    "for i in stop:\n",
    "    if i in positive:\n",
    "        ps+=1\n",
    "    elif i in negative:\n",
    "        ns+=1\n",
    "    else:\n",
    "        es+=1\n",
    "\n",
    "def print_stop_percentage():\n",
    "    print('Sentiment distribution for',a,'without stop words')\n",
    "    print('Positive:', procent(ps, stop), 'Negative:', procent(ns, stop), 'Neutral:' + procent(es, stop))\n",
    "\n",
    "def pie_stop_chart():\n",
    "    dane=[ps,ns,es]\n",
    "    labels=['Positive','Negative','Neutral']\n",
    "    plt.pie(dane,labels=labels,autopct='%1.2f%%',colors=['g','r','gold'])\n",
    "    k=('Sentiment Analysis without stop words for: '+a)\n",
    "    print(k)\n",
    "    plt.title(k)\n",
    "    plt.show()\n",
    "\n",
    "def sent_key(key):\n",
    "    key_list=[]\n",
    "    for sentence in sentences:\n",
    "        c=sentence.split()\n",
    "        if key in c:\n",
    "            key_list.append(sentence)\n",
    "    str=''.join(key_list)\n",
    "    key_list=str.split()\n",
    "    return key_list\n",
    "\n",
    "q=True\n",
    "while q:\n",
    "    print(\"\"\"What do you want to do?\n",
    "1 - show sentiment distribution in a text\n",
    "2 - show a pie chart of sentiment distribution\n",
    "3 - show a list of all positive words\n",
    "4 - show a list of all negative words\n",
    "5 - show a chart with top positive words\n",
    "6 - show a chart with top negative words\n",
    "7 - show sentiment distribution for text without redundant words\n",
    "8 - show a pie chart of sentiment distribution for text without redundant words\n",
    "9 - show sentiment distribution for sentences with provided keyword\n",
    "10 - quit \"\"\")\n",
    "    q=int(input(\"\"\"Press the number:\"\"\"))\n",
    "    if q==1:\n",
    "       print_percentage()\n",
    "    elif q == 2:\n",
    "        pie_chart()\n",
    "    elif q == 3:\n",
    "        pos_words_list()\n",
    "    elif q == 4:\n",
    "        neg_words_list()\n",
    "    elif q == 5:\n",
    "        pos_chart()\n",
    "    elif q == 6:\n",
    "        neg_chart()\n",
    "    elif q == 7:\n",
    "        print_stop_percentage()\n",
    "    elif q == 8:\n",
    "        pie_stop_chart()\n",
    "    elif q == 9:\n",
    "        key = input(\"Provide a keyword:\").lower()\n",
    "        pk = 0\n",
    "        nk = 0\n",
    "        ek = 0\n",
    "        key_list=sent_key(key)\n",
    "        if len(key_list)>0:\n",
    "            for i in key_list:\n",
    "                if i in positive:\n",
    "                    pk += 1\n",
    "                elif i in negative:\n",
    "                    nk += 1\n",
    "                else:\n",
    "                    ek += 1\n",
    "            print('Sentiment distribution for',a,'for sentences with key word')\n",
    "            print('Positive:', procent(pk, key_list), 'Negative:', procent(nk, key_list), 'Neutral:' + procent(ek, key_list))\n",
    "        else:\n",
    "            print(\"The word does not occur\")\n",
    "    elif q == 10:\n",
    "        print(\"Adi√≥s!\")\n",
    "        q=None\n",
    "    else:\n",
    "        print(\"Sorry, I don't understand.Provide a number from 1 to 10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'sentiment'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-b8669cb7186e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m     \u001b[0mtraining_corpus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTweets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentiment\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[0mtest_corpus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   4370\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4371\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4372\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4374\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'sentiment'"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "import os\n",
    "#os.chdir('/tmp/guest-pltjjp/Downloads')\n",
    "\n",
    "\n",
    "#data = pd.read_csv('text_emotion.csv')\n",
    "data = data.iloc[:20,:]\n",
    "\n",
    "\n",
    "#stopset = set(stopwords.words('english'))\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "#comprehensive cleaning\n",
    "def cleaning(text):\n",
    "    txt = str(text)\n",
    "    txt = re.sub(r\"http\\S+\", \"\", txt)\n",
    "    if len(txt) == 0:\n",
    "        return 'no text'\n",
    "    else:\n",
    "        txt = txt.split()\n",
    "        index = 0\n",
    "        for j in range(len(txt)):\n",
    "            if txt[j][0] == '@':\n",
    "                index = j\n",
    "        txt = np.delete(txt, index)\n",
    "        if len(txt) == 0:\n",
    "            return 'no text'\n",
    "        else:\n",
    "            words = txt[0]\n",
    "            for k in range(len(txt)-1):\n",
    "                words+= \" \" + txt[k+1]\n",
    "            txt = words\n",
    "            txt = re.sub(r'[^\\w]', ' ', txt)\n",
    "            if len(txt) == 0:\n",
    "                return 'no text'\n",
    "            else:\n",
    "                txt = ''.join(''.join(s)[:2] for _, s in itertools.groupby(txt))\n",
    "                txt = txt.replace(\"'\", \"\")\n",
    "                txt = nltk.tokenize.word_tokenize(txt)\n",
    "                #data.content[i] = [w for w in data.content[i] if not w in stopset]\n",
    "                for j in range(len(txt)):\n",
    "                    txt[j] = lem.lemmatize(txt[j], \"v\")\n",
    "                if len(txt) == 0:\n",
    "                    return 'no text'\n",
    "                else:\n",
    "                    return txt\n",
    "                \n",
    "data['Tweets'] = data['Tweets'].map(lambda x: cleaning(x))\n",
    "\n",
    "\n",
    "        \n",
    "data = data.reset_index(drop=True)\n",
    "for i in range(len(data)):\n",
    "    words = data.Tweets[i][0]\n",
    "    for j in range(len(data.Tweets[i])-1):\n",
    "        words+= ' ' + data.Tweets[i][j+1]\n",
    "    data.Tweets[i] = words\n",
    "    \n",
    "x = int(np.round(len(data)*0.75))\n",
    "train = data.iloc[:x,:].reset_index(drop = True)\n",
    "test = data.iloc[x:,:].reset_index(drop = True)\n",
    "    \n",
    "from textblob.classifiers import NaiveBayesClassifier as NBC\n",
    "\n",
    "training_corpus = []\n",
    "\n",
    "for k in range(len(train)):\n",
    "    training_corpus.append((train.Tweets[k], train.sentiment[k]))\n",
    "    \n",
    "test_corpus = []\n",
    "\n",
    "for l in range(len(test)):\n",
    "    test_corpus.append((test.Tweets[l], test.sentiment[l]))\n",
    "\n",
    "model = NBC(training_corpus)\n",
    "\n",
    "print(model.accuracy(test_corpus))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions = []\n",
    "for m in range(len(test)):\n",
    "    predictions.append(model.classify(test.Tweets[m]))\n",
    "print(classification_report(test.sentiment, predictions))\n",
    "    \n",
    "predictions_df = pd.DataFrame({'Content':test.Tweets, 'Emotion_predicted':predictions, 'Emotion_actual':test.sentiment})\n",
    "predictions_df.to_csv('naive_emotion_recognizer.csv', index = False)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print (\"processing time:\", elapsed_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realtime Tweet Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "illinoisConser1 2020-10-31 06:37:16 RT @LaylaAlisha11: The Electoral College Prediction That Will Leave the Left 'Terribly Shocked'!\n",
      "Trump has guts, willingness &amp; toughness to‚Ä¶\n",
      "Johnnsiegbe1 2020-10-31 06:37:16 Northern Nigeria to seize the White House from President Trump \n",
      "\n",
      "Pennsylvania, OHIO &amp; Florida  please do not allow‚Ä¶ https://t.co/Xs3seHhqBN\n",
      "g5marketnet 2020-10-31 06:37:16 RT @ABC: Speaker Nancy Pelosi slammed Trump administration's pandemic response: \"It's sinful! It's sinful that we have not addressed protec‚Ä¶\n",
      "AnneQuestion 2020-10-31 06:37:16 RT @cjtruth: WAS THERE REALLY ANY DOUBT?  If you listened to the fake news media you would think that Trump was going to lose everywhere.‚Ä¶\n",
      "bells_within 2020-10-31 06:37:16 RT @Evan_Rosenfeld: Stanford University study: ‚ÄúOur results suggest that [President Trump‚Äôs] rallies have resulted in more than 30,000 incr‚Ä¶\n",
      "WilliamQuake1 2020-10-31 06:37:16 @777djt @Raymond999USA @USAGOD1 The Gentlemen is a Chinese speaker and a Christian, I have no problem with this get‚Ä¶ https://t.co/jlpKO7pi6p\n",
      "Simmasongb 2020-10-31 06:37:16 @charliekirk11 @NickMalyon1 To my friends across the pond please watch https://t.co/yNaofS7GmX\n",
      "and look at what Pel‚Ä¶ https://t.co/fUT0Yf1wcc\n",
      "karennharoo 2020-10-31 06:37:16 RT @momsdontrave: vote for trump or do coke\n",
      "\n",
      "me:\n",
      "miguanabo 2020-10-31 06:37:16 RT @brad_polumbo: unhinged and hateful\n",
      "deepdavey 2020-10-31 06:37:16 RT @DGPurser: BREAKING:\n",
      "Brett Favre endorses Donald Trump, on the same day he holds a rally in Green Bay.\n",
      "\n",
      "Media: crickets. https://t.co/Jv‚Ä¶\n",
      "ShemuelMeir 2020-10-31 06:37:16 ◊°◊ò◊ô◊ë◊ü ◊û◊ô◊ú◊®, ◊©◊ê◊ô◊†◊ï ◊û◊™◊û◊¶◊ê ◊ï◊ê◊ô◊†◊ï ◊û◊ë◊ô◊ü ◊ê◊™ ◊û◊©◊û◊¢◊ï◊™ ◊§◊°◊ú ◊î◊ó◊ô◊®◊ï◊™ ◊ë◊õ◊†◊ô◊°◊î ◊ú◊†◊ô◊ï ◊ô◊ï◊®◊ß, ◊ï◊í◊ù ◊ô◊ï◊¢◊¶◊ï ◊î◊ô◊î◊ï◊ì◊ô ◊î◊ß◊®◊ï◊ë ◊©◊ú ◊ò◊®◊û◊§: ◊û◊ë◊ò◊ô◊ó ◊ß◊ì◊†‚Ä¶ https://t.co/1IbnIrrqwa\n"
     ]
    },
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'charmap' codec can't encode characters in position 33-37: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-92d89017884d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[0mstreamingAPI\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstreaming\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCustomStreamListener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m \u001b[0mstreamingAPI\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Trump'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Biden'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36mfilter\u001b[1;34m(self, follow, track, is_async, locations, stall_warnings, languages, encoding, filter_level)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'filter_level'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilter_level\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'delimited'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'length'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_async\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m     def sitestream(self, follow, stall_warnings=False,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_start\u001b[1;34m(self, is_async)\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    318\u001b[0m             \u001b[1;31m# call a handler first so that the exception can be logged.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m             \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    691\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    287\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msnooze_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msnooze_time_step\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_connect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mssl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSLError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m                 \u001b[1;31m# This is still necessary, as a SSLError can actually be\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_read_loop\u001b[1;34m(self, resp)\u001b[0m\n\u001b[0;32m    349\u001b[0m             \u001b[0mnext_status_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_len\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnext_status_obj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 351\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_status_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m             \u001b[1;31m# # Note: keep-alive newlines might be inserted before each length value.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36mon_data\u001b[1;34m(self, raw_data)\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'in_reply_to_status_id'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mstatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;34m'delete'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-92d89017884d>\u001b[0m in \u001b[0;36mon_status\u001b[1;34m(self, status)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'OutputStreaming.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'a'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauthor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscreen_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreated_at\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalEncoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'charmap' codec can't encode characters in position 33-37: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tweepy\n",
    "import csv\n",
    "\n",
    "#pass security information to variables\n",
    "consumer_key = 'Fkq1YtWMXJfm7rqFQe6bUMKnk'\n",
    "consumer_secret = 'tbQFEXaYskF6vfHMN0xpBhjuDGIYP6vpNk4TYEsbn3ETOj6YKY'\n",
    "access_token = '1254116935006072833-4lYrmDIsHq9wbVan3VDtdzwkeWe6Nc'\n",
    "access_token_secret = 'f9zpd5uYABZCiK28Cixp5kR3dy6bFbXybDfwiWRMFvaa3'\n",
    "\n",
    "\n",
    "\n",
    "#use variables to access twitter\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#create an object called 'customStreamListener'\n",
    "\n",
    "class CustomStreamListener(tweepy.StreamListener):\n",
    "\n",
    "    def on_status(self, status):\n",
    "        print (status.author.screen_name, status.created_at, status.text)\n",
    "        # Writing status data\n",
    "        with open('OutputStreaming.txt', 'a') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([status.author.screen_name, status.created_at, status.text])\n",
    "\n",
    "\n",
    "    def on_error(self, status_code):\n",
    "        print >> sys.stderr, 'Encountered error with status code:', status_code\n",
    "        return True # Don't kill the stream\n",
    "\n",
    "    def on_timeout(self):\n",
    "        print >> sys.stderr, 'Timeout...'\n",
    "        return True # Don't kill the stream\n",
    "\n",
    "# Writing csv titles\n",
    "with open('OutputStreaming.txt', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Author', 'Date', 'Text'])\n",
    "\n",
    "streamingAPI = tweepy.streaming.Stream(auth, CustomStreamListener())\n",
    "streamingAPI.filter(track=['Trump', 'Biden'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twitter_stream_listener(file_name,\n",
    "                            filter_track,\n",
    "                            follow=None,\n",
    "                            locations=None,\n",
    "                            languages=None,\n",
    "                            time_limit=20):\n",
    "    class CustomStreamListener(tweepy.StreamListener):\n",
    "        def __init__(self, time_limit):\n",
    "            self.start_time = time.time()\n",
    "            self.limit = time_limit\n",
    "            # self.saveFile = open('abcd.json', 'a')\n",
    "            super(CustomStreamListener, self).__init__()\n",
    "        def on_status(self, status):\n",
    "            if (time.time() - self.start_time) < self.limit:\n",
    "                print(\".\", end=\"\")\n",
    "                # Writing status data\n",
    "                with open(file_name, 'a') as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    writer.writerow([\n",
    "                        status.author.screen_name, status.created_at,\n",
    "                        status.text\n",
    "                    ])\n",
    "            else:\n",
    "                print(\"\\n\\n[INFO] Closing file and ending streaming\")\n",
    "                return False\n",
    "        def on_error(self, status_code):\n",
    "            if status_code == 420:\n",
    "                print('Encountered error code 420. Disconnecting the stream')\n",
    "                # returning False in on_data disconnects the stream\n",
    "                return False\n",
    "            else:\n",
    "                print('Encountered error with status code: {}'.format(\n",
    "                    status_code))\n",
    "                return True  # Don't kill the stream\n",
    "        def on_timeout(self):\n",
    "            print('Timeout...')\n",
    "            return True  # Don't kill the stream\n",
    "    # Writing csv titles\n",
    "    print(\n",
    "        '\\n[INFO] Open file: [{}] and starting {} seconds of streaming for {}\\n'\n",
    "        .format(file_name, time_limit, filter_track))\n",
    "    with open(file_name, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['author', 'date', 'text'])\n",
    "    streamingAPI = tweepy.streaming.Stream(\n",
    "        auth, CustomStreamListener(time_limit=time_limit))\n",
    "    streamingAPI.filter(\n",
    "        track=filter_track,\n",
    "        follow=follow,\n",
    "        locations=locations,\n",
    "        languages=languages,\n",
    "    )\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Open file: [TrumpvsBiden.csv] and starting 60 seconds of streaming for ['Trump', 'Biden']\n",
      "\n",
      "......."
     ]
    },
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'charmap' codec can't encode character '\\U0001f6a8' in position 47: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-aebc08bc337c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfilter_track\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Trump'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Biden'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m'TrumpvsBiden.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtwitter_stream_listener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfilter_track\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtime_limit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-34-6649cc0d5a7d>\u001b[0m in \u001b[0;36mtwitter_stream_listener\u001b[1;34m(file_name, filter_track, follow, locations, languages, time_limit)\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mfollow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mlocations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlocations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mlanguages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlanguages\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m     )\n\u001b[0;32m     53\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36mfilter\u001b[1;34m(self, follow, track, is_async, locations, stall_warnings, languages, encoding, filter_level)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'filter_level'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilter_level\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'delimited'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'length'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_async\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m     def sitestream(self, follow, stall_warnings=False,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_start\u001b[1;34m(self, is_async)\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    318\u001b[0m             \u001b[1;31m# call a handler first so that the exception can be logged.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m             \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    691\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    287\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msnooze_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msnooze_time_step\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_connect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mssl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSLError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m                 \u001b[1;31m# This is still necessary, as a SSLError can actually be\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_read_loop\u001b[1;34m(self, resp)\u001b[0m\n\u001b[0;32m    349\u001b[0m             \u001b[0mnext_status_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_len\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnext_status_obj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 351\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_status_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m             \u001b[1;31m# # Note: keep-alive newlines might be inserted before each length value.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36m_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tweepy\\streaming.py\u001b[0m in \u001b[0;36mon_data\u001b[1;34m(self, raw_data)\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'in_reply_to_status_id'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mstatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;34m'delete'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-6649cc0d5a7d>\u001b[0m in \u001b[0;36mon_status\u001b[1;34m(self, status)\u001b[0m\n\u001b[0;32m     19\u001b[0m                     writer.writerow([\n\u001b[0;32m     20\u001b[0m                         \u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauthor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscreen_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreated_at\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m                         \u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m                     ])\n\u001b[0;32m     23\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalEncoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'charmap' codec can't encode character '\\U0001f6a8' in position 47: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "filter_track=['Trump','Biden']\n",
    "file_name= 'TrumpvsBiden.csv'\n",
    "twitter_stream_listener(file_name,filter_track,time_limit=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x92 in position 72: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._string_box_utf8\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x92 in position 72: invalid start byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-828455a80275>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"TrumpvsBiden.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1034\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'skipfooter not supported for iteration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1036\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1037\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1846\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._string_box_utf8\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x92 in position 72: invalid start byte"
     ]
    }
   ],
   "source": [
    "df= pd.read_csv(\"TrumpvsBiden.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-e0d51d49ea56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mporter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSTOPWORDS\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_cloud(wd_list):\n",
    "    stopwords = set(STOPWORDS)\n",
    "    all_words = ' '.join([text for text in wd_list])\n",
    "    wordcloud = WordCloud(\n",
    "        background_color='white',\n",
    "        stopwords=stopwords,\n",
    "        width=1600,\n",
    "        height=800,\n",
    "        random_state=21,\n",
    "        colormap='jet',\n",
    "        max_words=50,\n",
    "        max_font_size=200).generate(all_words)\n",
    "\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_tw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-421fb80fb335>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Positive - Original dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtw_pos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_tw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_tw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Sentiment'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SentimentText'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mword_cloud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtw_pos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_tw' is not defined"
     ]
    }
   ],
   "source": [
    "#Positive - Original dataset\n",
    "tw_pos = df_tw[df_tw['Sentiment'] == 1]['SentimentText']\n",
    "word_cloud(tw_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
